# GAN
这是在下GAN项目的学习过程

## 最初的GAN(2014 Ian Goodfellow)
Ian Goodfellow 等人在 2014 年的论文中提出了生成式对抗网络，尽管这个想法几乎立刻使研究人员们兴奋不已，但还是花了几年时间才克服了 GAN 的一些困难。就像许多伟大的想法一样，事后看起来似乎很简单:让神经网络相互竞争，希望这种竞争能够促使它们变得更好。
* 生成器:以随机分布作为输入 (通常是高斯分布)，并输出一些数据 (通常是图像)。可以将随即输入视为要生成图像的潜在表征 (即编码)。因此生成器提供的功能与变分自动编码器中的解码器相同，并且可以使用相同的方式来生成新图像。但它们的训练方式大不相同。
* 判别器:输入从生成器得到的伪图像或从训练集中得到的真实图像，并且必须猜测输入图像是伪图像还是真实图像。
 
在训练过程中，生成器和判别器有相反的目标:判别器试图从真实图像中分辨出虚假图像，而生成器则试图长生看起来足够真实的图像来欺骗判别器。由于 GAN 由不同目标的两个网络组成，因此无法像常规网络一样对其进行训练。每个训练迭代都分为两个阶段:
* 在第一阶段，我们训练判别器。从训练集中采样一批真实图像，再加上用生成器生成的相等数量的伪图像组成训练批次。对于伪图像，将标签设置为 0;对于真是图像，将标签设置为 1，并使用二元交叉熵损失在该被标签的批次上对判别器进行训练。重要的是，在这个阶段反向传播**只能优化判别器的权重**。
* 在第二阶段，我们训练生成器。首先使用它来生成另一批伪图像，然后再次使用判别器来判断图像是伪图像还是真实图像。在这个批次中不添加真实图像，并且所有标签都设置为 1(真实)，即我们希望生成器能产生判别器会 (错误地) 认为是真实的图像!至关重要的是，在此步骤中，**判别器的权重会被固定，因此反向传播只会影响生成器的权重**。

生成器实际上从未看到过任何真实的图像，但是它逐渐学会产生令人信服的伪图像!它所得到的是流经判别器的回流梯度。幸运的是，判别器越好，这些二手梯度中包含的真实图像信息就越多，因此生成器可以取得很大进步。下面为 Fashion MNIST 构建一个简单的 GAN:[GAN_1code](https://github.com/ly-gump/GAN/blob/main/GAN-codes/GAN-start.ipynb)。

## GAN的训练难点
* 最大的困难被称为模式崩溃:就是当生成器的输出逐渐变得不太多样化时。GAN 可能会逐渐在几个类别中循环，而不会擅长生成任何一个类别。
* 此外由于发生器和判别器不断地相互竞争，因此它们的参数可能最终会振荡并变得不稳定。训练开始时可能会很好，然后由于这些不稳定而突然发散，没有明显的原因。而且有许多因素会影响这些复杂的动态过程，因此 GAN对超参数非常敏感，可能不得不花费大量的经历来微调它们。

## DCGAN
构建稳定的卷积 GAN 提出的主要指导：
* 用跨步卷积 (在判别器中) 和转置卷积 (在生成器中) 替换所有池化层。
* 除生成器的输出层和判别器的输入层外，在生成器和判别器中都是用批量归一化。
* 删除全连接的隐藏层以获得更深的架构。
* 对生成器中的所有层使用 ReLU 激活函数，除了输出层应该使用tanh。
* 对判别器中的所有层使用 leaky ReLU 激活函数。
这些准则在许多情况下都会起作用，但并非总是如此，因此可能需要试验不同的超参数 (实际上，仅仅更改随机种子并在此训练相同的模型有时会起作用)。如下述的小型DCGAN，在 Fashion MNIST 数据集上可以很好地工作:

## StyleGAN
Nvidia 团队在 2018 年发表的一篇论文中提出了高分辨率图像生成的最新技术，该论文介绍了流行的 StyleGAN 架构。作者在生成器中使用了风格转换技术，以确保生成的图像在各个尺度上都具有与训练图像相同的内部结构，从而极大地提高了所生成的图像质量。判别器和损失函数没有被修改，仅仅修改了生成器，生成器由映射网络与合成网络组成：
![StyleGAN](https://github.com/ly-gump/GAN/blob/main/figures/StyleGAN.png)
* 映射网络:一个 8 层的 MLP 把潜在表示 z(即编码) 映射到向量 w。然后，通过多个仿射变换(没有激活函数的 Dense 层)发送此向量，从而生成多个向量。简而言之，映射网络将编码映射到多个风格向量。
* 合成网络:负责生成图像。它具有恒定的学习输入 (需要明确的是，此输入在训练后将保持不变，但是在训练过程中，它会经过反向传播而不断调整)。如前所述，它通过多个卷积和上采样层处理此输入，但有两处调整:首先，在卷积层的输入和所有输出中添加了一些噪声 (在激活函数之前)。其次，每个噪声层后面是一个自适应实例归一化 (AdaIN) 层:它独立地归一化每个特征图 (减去特征图的均值并除以其标准差)，然后使用风格向量确定每个特征图的比例和偏移量 (风格向量为每个特征图包含一个比例和一个偏置项)。

独立于编码来增加噪声的想法非常重要，图像的某些部分非常随机。在较早的 GAN 中，这种随机性要么来自编码，要么是生成器自身产生的一些伪随机噪声，这些都有一定的问题。通过增加额外的噪声输入，可以避免所有这些问题。GAN 能够使用所提供的噪声为图像的每个部分添加适当数量的随机性。

最后，StyleGAN 使用一种称为混合正则化 (或风格混合) 的技术，使用两种不同的编码生成一定百分比的生成图像。如编码 c1 和编码 c2 通过映射网络发送，给出两个风格向量 w1 和 w2。然后，合成网络基于第一个级别的风格 w1 和其余级别的样式 w2 生成图像。截断级别是随机选择的。这可以防止网络假设相邻级别的风格是相关联的，这反过来又鼓励了 GAN 中的局部性，意味着每个风格向量仅影响所生成图像中有限数量的特征。


